---
title: "MLE - Data 3"
description: "Professor: Andy Philips"
author:
  - name: Stone Neilon
    url: https://stoneneilon.github.io/
    orcid: 0009-0006-6026-4384
    affiliation: PhD student of political science @ The University of Colorado Boulder
    affiliation-url: https://www.colorado.edu/polisci/people/graduate-students/stone-neilon
date: 08-26-2024
categories: [2024, Methods, Fall] # self-defined categories
citation: 
  url: https://stoneneilon.github.io/notes/Comparative_Behavior/
image: jamiexx.webp
draft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
---

# [Syllabus](https://www.dropbox.com/scl/fi/32ji3ucw54taatfon4ja4/MLE-syllabus.pdf?rlkey=jhqzrrb2ymqxg70s7wuwzeeyr&st=taxpe036&dl=0)

# Topic 1 - Introduction to Probability Models

## Required Reading:

### King Chapters 1 & 2

#### Chapter 1: 

-   Introduction of the book. Political science methodology is disjointed and not as completely coherent as it should (and needs) to be. King seeks to organize and centralize the political science methodology.

-   Statistic Model: a formal representation of the *process* by which a social system produces output.

    -   Since no interesting social systems generate outcomes deterministically, statistical models are assumed to have both systematic and stochastic components.

-   **Inference:** the general process by which one uses observed data to learn about the social system and its outputs.

-   **Estimation:** the specific procedure by which one obtains estimates of features (usually parameters) of the statistical model.

-   **The important question for political science research:**

    -   is the underlying process that gives rise to the observed data

        -   What are the characteristics of the social system that produced these data?

        -   What changes in known features of the social system might have produced data with different characteristics?

        -   What is the specific stochastic process driving one's results?

    -   By posing these questions, statistical modelling will be more theoretically relevant and empirically fruitful.

#### Chapter 2: 

### Ward and Ahlquist Chapter 1: 

## Lecture: 

[Week 1 Slides](https://www.dropbox.com/scl/fi/n8anv7gle9cit9sp8v329/MLE-week1-Handout.pdf?rlkey=38st1zfju2yrsyh0ybgw51zw5&st=8rnk9udt&dl=0)

-   Summary: Run models that find parameters that are most likely to have generated the observed data.

-   These models are hard to interpret.

-   Goal: Familiarize you with a variety of MLE models used in the social sciences.

-   Probability has to sum to 1.

    -   We want to find the best estimate $\theta$

-   Probabilities are:

    -   Bounded between 1 and 0.

    -   Sum of probabilities equal 1.

    -   Trials -\> $\infty$

    -   Mutually exclusive outcomes.

-    Theta is the only parameter we need to estimate.

-   We are still specifying the distribution of the outcome variable. Is it a poisson, bernoulli, normal, etc?

    -   this will help us specify which model to use.

-   L stands for "likelihood function"

-   Our goal is to select some $\theta$\* -\> $\hat{\theta}$ as to maximize the likelihood of these data being generated. Ways to do this:

    -   plug in candidate $\theta$\* values

    -   look at the graph

    -   optimize function (solve for $\theta$\*)

-   No priors! (that would be Bayesian)

    -   for our coin flip example, we know .5 is the probability but we only have a set of {H,H,T}

    -   Without anymore knowledge, the best estimate of $\theta$ is 2/3 or .66.

-   We use ML anytime our dependent variable has a distribution that was not generated by a Gaussian (normal) process.

    -   see slide 23 for examples.

    -   We can estimate all of these using OLS but we may hit a few snags and violation assumptions.

## Homework 1: 

-   "Lab 1.R"
